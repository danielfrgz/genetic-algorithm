{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace35d88-71b7-49e3-b719-f4445bee3960",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Particle Swarm Optimization Implementation\n",
    "\n",
    "Developed by Daniel Frutos Rodriguez for _\"A Comparison of Optimization Techniques for Solving the Team Formation Problem\"_.\n",
    "\n",
    "Frutos-Rodriguez D., Barrios-Fleitas Y., and Lalla E. 2025. _A Comparison of Optimization Techniques for Solving the Team Formation Problem._ In _Proceedings Placeholder_. ACM, New York, NY, USA, 6 pages. [https://doi.org/10.1145/nnnnnnn.nnnnnnn](https://doi.org/10.1145/nnnnnnn.nnnnnnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf571ca",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b68556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # For datasets\n",
    "import utils.fitness_functions as ff\n",
    "import utils.monoobjective_exhaustive_solver as es\n",
    "import utils.restriction_checker as rc\n",
    "import models.team_assignment as ta\n",
    "import random # For randomness\n",
    "import os # For output\n",
    "from contextlib import redirect_stdout # For output\n",
    "import datetime # For output\n",
    "from copy import deepcopy # For velocity function\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a3b2b",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9294e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "PROJECTS = ['Shotmaniacs', 'actFact', 'Honours Programme', 'Voice', 'Topicus', 'Earnit', 'Inter-actief'] # Possible projects.\n",
    "DATA = 'data/dataset_small.csv' # Dataset reference.\n",
    "DATASET = pd.read_csv(DATA) # Dataset stored as a dataframe.\n",
    "\n",
    "# Safeguards\n",
    "\n",
    "MAX_RANDOM_SWAP_ATTEMPTS = 10\n",
    "\n",
    "# Tuning Parameters\n",
    "\n",
    "W = 0.5\n",
    "\n",
    "C1 = 0.25\n",
    "\n",
    "C2 = 0.75\n",
    "\n",
    "# Experimental controls\n",
    "\n",
    "NUMBER_OF_ITERATIONS = 100 # Number of generations to iterate in the PSO loop.\n",
    "SWARM_SIZE = 10 # Number of particles per swarm in each iteration of the PSO.\n",
    "COMPUTE_OPTIMAL_SOLUTION = False # (Only for small synthetic datasets), computes optimal solution through exhaustive solver.\n",
    "EFFICIENCY_GOAL = None # (Only for small synthetic datasets), allows early finishing of the algorithm if a certain efficiency\n",
    "                     # (score / score of best possible solution) is met.\n",
    "\n",
    "# Output constants\n",
    "\n",
    "RUN_TIME = datetime.datetime.now().strftime(\"run_%Y%m%d_%H%M%S\") # Constant for output folder naming.\n",
    "BASE_DIR = \"output/pso\" # Base directory for outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f0a52",
   "metadata": {},
   "source": [
    "#### Output Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd29fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_arrangement_batch(arrangements, iteration, run_time=RUN_TIME):\n",
    "    # Create output directory\n",
    "    os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "    run_folder = os.path.join(BASE_DIR, f\"{run_time}\", f\"generation_{iteration}\")\n",
    "    os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Evaluate and save each arrangement\n",
    "    for i, arrangement in enumerate(arrangements, start=1):\n",
    "        filename = os.path.join(run_folder, f\"assignment_{i}.txt\")\n",
    "        with open(filename, \"w\") as f:\n",
    "            with redirect_stdout(f):\n",
    "                score = ff.evaluate_all_teams(arrangement)\n",
    "                print(f\"\\nFinal score for arrangement {i}: {score:.4f}\")\n",
    "                scores.append(score)\n",
    "                \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046752d6",
   "metadata": {},
   "source": [
    "#### Initial Population Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420929c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_teams(df, min_size=5, max_size=6, project_pool=PROJECTS):\n",
    "    students = df.to_dict(orient='records')\n",
    "    random.shuffle(students)\n",
    "\n",
    "    total_students = len(students)\n",
    "    remainder = total_students % min_size\n",
    "    num_six_person_teams = remainder\n",
    "    num_five_person_teams = (total_students - (max_size * num_six_person_teams)) // min_size\n",
    "    total_teams = num_five_person_teams + num_six_person_teams\n",
    "\n",
    "    def assign_projects_to_teams(num_teams, projects):\n",
    "        base = num_teams // len(projects)\n",
    "        extra = num_teams % len(projects)\n",
    "        project_assignments = []\n",
    "        for idx, project in enumerate(projects):\n",
    "            count = base + (1 if idx < extra else 0)\n",
    "            project_assignments.extend([project] * count)\n",
    "        random.shuffle(project_assignments)\n",
    "        return project_assignments\n",
    "\n",
    "    project_assignments = assign_projects_to_teams(total_teams, project_pool)\n",
    "    project_counters = {proj: 0 for proj in project_pool}\n",
    "\n",
    "    teams = []\n",
    "\n",
    "    for _ in range(num_six_person_teams):\n",
    "        team = []\n",
    "        tcs_count = 0\n",
    "        nationality_counts = {}\n",
    "\n",
    "        while len(team) < max_size:\n",
    "            valid_candidates = [\n",
    "                s for s in students\n",
    "                if ('TCS' not in s['Program'] or tcs_count < 4)\n",
    "                and (s['Nationality'] == 'Dutch' or nationality_counts.get(s['Nationality'], 0) < 3)\n",
    "            ]\n",
    "\n",
    "            selected = random.choice(valid_candidates)\n",
    "            team.append(selected)\n",
    "            students.remove(selected)\n",
    "\n",
    "            if 'TCS' in selected['Program']:\n",
    "                tcs_count += 1\n",
    "            if selected['Nationality'] != 'Dutch':\n",
    "                nationality_counts[selected['Nationality']] = nationality_counts.get(selected['Nationality'], 0) + 1\n",
    "\n",
    "        project = project_assignments[len(teams)]\n",
    "        project_counters[project] += 1\n",
    "        team_id = f\"{project} {project_counters[project]}\"\n",
    "        teams.append(ta.TeamAssignment(team_id, team, project, fitness=0.0))\n",
    "\n",
    "    for _ in range(num_five_person_teams):\n",
    "        team = []\n",
    "        tcs_count = 0\n",
    "        nationality_counts = {}\n",
    "\n",
    "        while len(team) < min_size:\n",
    "            valid_candidates = [\n",
    "                s for s in students\n",
    "                if ('TCS' not in s['Program'] or tcs_count < 4)\n",
    "                and (s['Nationality'] == 'Dutch' or nationality_counts.get(s['Nationality'], 0) < 3)\n",
    "            ]\n",
    "            if not valid_candidates:\n",
    "                return None\n",
    "\n",
    "            selected = random.choice(valid_candidates)\n",
    "            team.append(selected)\n",
    "            students.remove(selected)\n",
    "\n",
    "            if 'TCS' in selected['Program']:\n",
    "                tcs_count += 1\n",
    "            if selected['Nationality'] != 'Dutch':\n",
    "                nationality_counts[selected['Nationality']] = nationality_counts.get(selected['Nationality'], 0) + 1\n",
    "\n",
    "        project = project_assignments[len(teams)]\n",
    "        project_counters[project] += 1\n",
    "        team_id = f\"{project} {project_counters[project]}\"\n",
    "        teams.append(ta.TeamAssignment(team_id, team, project, fitness=0.0))\n",
    "\n",
    "    return teams if rc.is_valid_arrangement(teams, total_students, project_pool) else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9486e0",
   "metadata": {},
   "source": [
    "#### Particle Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af473ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, dataset, projects, min_size=5, max_size=6):\n",
    "        self.dataset = dataset\n",
    "        self.projects = projects\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "        self.position = self.random_position()\n",
    "        self.velocity = [] # List of swaps: (Origin, Destination, Student_1, Student_2) 4-tuples\n",
    "        self.best_position = deepcopy(self.position)\n",
    "        self.best_fitness = -1\n",
    "\n",
    "    def random_position(self):\n",
    "        arrangement = None\n",
    "        while arrangement is None:\n",
    "            arrangement = create_random_teams(self.dataset)\n",
    "        return arrangement\n",
    "\n",
    "    def update_velocity(self, pbest_pos, gbest_pos, w, c1, c2, attempted_arrangements):\n",
    "\n",
    "        def get_team_of_student(teams, student_id):\n",
    "            for i, team in enumerate(teams):\n",
    "                if any(member['ID'] == student_id for member in team.members):\n",
    "                    return i\n",
    "            return None\n",
    "\n",
    "        def generate_swaps(source, target):\n",
    "            swaps = []\n",
    "            for team_a_idx, team_a in enumerate(source):\n",
    "                for member_a in team_a.members:\n",
    "                    student_id = member_a['ID']\n",
    "                    team_b_idx = get_team_of_student(target, student_id)\n",
    "                    if team_b_idx is not None and team_b_idx != team_a_idx:\n",
    "                        # Try to find a member from team_b to swap with\n",
    "                        team_b = source[team_b_idx]\n",
    "                        for member_b in team_b.members:\n",
    "                            swaps.append((team_a_idx, team_b_idx, member_a['ID'], member_b['ID']))\n",
    "            return swaps\n",
    "\n",
    "        def simulate_and_validate(teams, swaps):\n",
    "            simulated = deepcopy(teams)\n",
    "            student_lookup = {m['ID']: m for team in simulated for m in team.members}\n",
    "\n",
    "            for a, b, id_a, id_b in swaps:\n",
    "                ta, tb = simulated[a], simulated[b]\n",
    "                ta.members = [m for m in ta.members if m['ID'] != id_a]\n",
    "                tb.members = [m for m in tb.members if m['ID'] != id_b]\n",
    "                ta.members.append(student_lookup[id_b])\n",
    "                tb.members.append(student_lookup[id_a])\n",
    "\n",
    "            valid, _ = rc.is_valid_arrangement(simulated, len(student_lookup), self.projects)\n",
    "            return valid\n",
    "\n",
    "        # --- Build candidate swaps ---\n",
    "        new_velocity = [(f, t, sa, sb) for f, t, sa, sb in self.velocity if random.random() < w]\n",
    "        cognitive_swaps = generate_swaps(self.position, pbest_pos)\n",
    "        social_swaps = generate_swaps(self.position, gbest_pos)\n",
    "\n",
    "        cognitive_part = [s for s in cognitive_swaps if random.random() < c1]\n",
    "        social_part = [s for s in social_swaps if random.random() < c2]\n",
    "\n",
    "        combined_swaps = new_velocity + cognitive_part + social_part\n",
    "\n",
    "        # --- Try building a valid velocity ---\n",
    "        valid_velocity = []\n",
    "        for swap in combined_swaps:\n",
    "            attempted_arrangements[0] += 1\n",
    "            trial = valid_velocity + [swap]\n",
    "            if simulate_and_validate(self.position, trial):\n",
    "                valid_velocity.append(swap)\n",
    "\n",
    "        # --- Fallback: try random single swaps ---\n",
    "        if not valid_velocity:\n",
    "            for _ in range(MAX_RANDOM_SWAP_ATTEMPTS):\n",
    "                attempted_arrangements[0] += 1\n",
    "                a, b = random.sample(range(len(self.position)), 2)\n",
    "                if not self.position[a].members or not self.position[b].members:\n",
    "                    continue\n",
    "                sa = random.choice(self.position[a].members)\n",
    "                sb = random.choice(self.position[b].members)\n",
    "                trial = [(a, b, sa['ID'], sb['ID'])]\n",
    "                if simulate_and_validate(self.position, trial):\n",
    "                    valid_velocity.append((a, b, sa['ID'], sb['ID']))\n",
    "                    break\n",
    "\n",
    "        self.velocity = valid_velocity\n",
    "\n",
    "    def fitness(self):\n",
    "        return ff.evaluate_all_teams(self.position)\n",
    "\n",
    "    def update_position(self):\n",
    "        new_particle = deepcopy(self.position)\n",
    "\n",
    "        def remove_student(team, student_id):\n",
    "            for i, member in enumerate(team.members):\n",
    "                if member['ID'] == student_id:\n",
    "                    return team.members.pop(i)\n",
    "            return None\n",
    "\n",
    "        for a, b, id_a, id_b in self.velocity:\n",
    "            sa = remove_student(new_particle[a], id_a)\n",
    "            sb = remove_student(new_particle[b], id_b)\n",
    "            if sa and sb:\n",
    "                new_particle[a].members.append(sb)\n",
    "                new_particle[b].members.append(sa)\n",
    "        self.position = new_particle\n",
    "\n",
    "    def update_velocity_and_position(self, gbest_pos, attempted_arrangements):\n",
    "        self.update_velocity(self.best_position, gbest_pos, W, C1, C2, attempted_arrangements)\n",
    "        self.update_position()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d3dfe",
   "metadata": {},
   "source": [
    "#### PSO Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba337ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute():\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"score\": pd.Series(dtype=\"float\"),\n",
    "        \"number of computations\": pd.Series(dtype=\"float\")\n",
    "    })\n",
    "\n",
    "    swarm = [Particle(DATASET, PROJECTS) for _ in range(SWARM_SIZE)]\n",
    "\n",
    "    # Computation of Best Possible Arrangement for Performance Measurement. Only feasible in small synthetic datasets due to TFP.\n",
    "    if (COMPUTE_OPTIMAL_SOLUTION):\n",
    "        optimal_arrangement, optimal_score, arrangements_computed = es.find_best_arrangement(DATASET, DATA)\n",
    "\n",
    "    global_best_position = None\n",
    "    global_best_fitness = -1\n",
    "    iters = 0\n",
    "    efficiency = -1\n",
    "    attempted_arrangements = [0]\n",
    "\n",
    "    run_time = datetime.datetime.now().strftime(\"run_%Y%m%d_%H%M%S\")\n",
    "    performance_log_path = os.path.join(BASE_DIR, f\"{run_time}\", \"performance.txt\")\n",
    "    os.makedirs(os.path.dirname(performance_log_path), exist_ok=True)\n",
    "\n",
    "    with open(performance_log_path, \"w\") as f:\n",
    "        f.write(f\"Performance log for run: {run_time}\\n\\n\")\n",
    "\n",
    "    while iters <= NUMBER_OF_ITERATIONS and (EFFICIENCY_GOAL is None or efficiency < EFFICIENCY_GOAL):\n",
    "        for particle in swarm:\n",
    "            fitness_val = particle.fitness()\n",
    "            if fitness_val > particle.best_fitness:\n",
    "                particle.best_fitness = fitness_val\n",
    "                particle.best_position = deepcopy(particle.position)\n",
    "            if fitness_val > global_best_fitness:\n",
    "                global_best_fitness = fitness_val\n",
    "                global_best_position = deepcopy(particle.position)\n",
    "\n",
    "        for particle in swarm:\n",
    "            particle.update_velocity_and_position(global_best_position, attempted_arrangements)\n",
    "\n",
    "        # Log the best score in the generation\n",
    "        if (COMPUTE_OPTIMAL_SOLUTION):\n",
    "            efficiency = round((global_best_fitness / optimal_score) * 100, 2)\n",
    "\n",
    "        with open(performance_log_path, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"Iteration {iters}: Best score = {global_best_fitness:.4f}\"\n",
    "                + (f\" | Efficiency = {efficiency:.2f}%\" if COMPUTE_OPTIMAL_SOLUTION else \"\")\n",
    "                + (f\" | Total Computations: {attempted_arrangements}\")\n",
    "                + (f\" of {arrangements_computed:.0f} Possible Combinations\" if COMPUTE_OPTIMAL_SOLUTION else \"\")\n",
    "                + \"\\n\"\n",
    "            )\n",
    "\n",
    "        # Save best arrangement of this iteration\n",
    "        save_arrangement_batch([p.position for p in swarm], iters, run_time)\n",
    "\n",
    "        iters += 1\n",
    "\n",
    "        df.loc[iters] = [global_best_fitness, attempted_arrangements[0]]\n",
    "\n",
    "    return df, global_best_position"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
